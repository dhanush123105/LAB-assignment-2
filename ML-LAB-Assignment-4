
# LAB 04 : kNN Classification Experiments
# Subject Code : 22AIE213
# Dataset      : Parkinson's Disease Dataset


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    confusion_matrix,
    precision_score,
    recall_score,
    f1_score,
    mean_squared_error,
    r2_score
)

#  A1

def train_knn(X_train, X_test, y_train, y_test, k):
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train, y_train)
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    return train_pred, test_pred

def compute_classification_metrics(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    return cm, precision, recall, f1

#  A2 

def compute_regression_metrics(y_actual, y_predicted):
    mse = mean_squared_error(y_actual, y_predicted)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((y_actual - y_predicted) / y_actual)) * 100
    r2 = r2_score(y_actual, y_predicted)
    return mse, rmse, mape, r2

#  A3 
def generate_training_points():
    np.random.seed(10)
    X = np.random.randint(1, 11, size=(20, 2))
    y = np.array([0 if (x[0] + x[1]) < 12 else 1 for x in X])
    return X, y

def plot_training_points(X, y):
    colors = ['blue' if label == 0 else 'red' for label in y]
    plt.scatter(X[:, 0], X[:, 1], c=colors)
    plt.xlabel("X Feature")
    plt.ylabel("Y Feature")
    plt.title("Training Data Scatter Plot")
    plt.show()

#  A4 & A5 

def generate_test_points():
    x = np.arange(0, 10, 0.1)
    y = np.arange(0, 10, 0.1)
    gx, gy = np.meshgrid(x, y)
    test_points = np.c_[gx.ravel(), gy.ravel()]
    return test_points

def classify_and_plot(X_train, y_train, test_points, k):
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train, y_train)
    predictions = model.predict(test_points)
    colors = ['blue' if p == 0 else 'red' for p in predictions]
    plt.scatter(test_points[:, 0], test_points[:, 1], c=colors, s=1)
    plt.title(f"kNN Classification (k = {k})")
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.show()

#  A6 

def load_parkinsons_data(file_path):
    data = pd.read_csv(file_path)
    X = data[['MDVP:Fo(Hz)', 'MDVP:Jitter(%)']]
    y = data['status']
    return X, y

#  A7 

def find_optimal_k(X_train, y_train):
    param_grid = {'n_neighbors': np.arange(1, 21)}
    knn = KNeighborsClassifier()
    grid = GridSearchCV(knn, param_grid, cv=5)
    grid.fit(X_train, y_train)
    return grid.best_params_, grid.best_score_

# MAIN PROGRAM 

# Load project dataset
X, y = load_parkinsons_data("parkinsons (1).csv")

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

train_pred, test_pred = train_knn(X_train, X_test, y_train, y_test, k=3)

train_cm, train_prec, train_rec, train_f1 = compute_classification_metrics(
    y_train, train_pred
)
test_cm, test_prec, test_rec, test_f1 = compute_classification_metrics(
    y_test, test_pred
)

print("Training Confusion Matrix:\n", train_cm)
print("Training Precision:", train_prec)
print("Training Recall:", train_rec)
print("Training F1 Score:", train_f1)

print("\nTest Confusion Matrix:\n", test_cm)
print("Test Precision:", test_prec)
print("Test Recall:", test_rec)
print("Test F1 Score:", test_f1)

X_train_2d, y_train_2d = generate_training_points()
plot_training_points(X_train_2d, y_train_2d)


test_points = generate_test_points()
for k in [1, 3, 5, 7]:
    classify_and_plot(X_train_2d, y_train_2d, test_points, k)


best_k, best_score = find_optimal_k(X_train, y_train)
print("\nBest k value found:", best_k)
print("Best Cross Validation Score:", best_score)

